# https://hub.docker.com/r/homme/gdal/
FROM geodata/gdal

# geodata/gdal sets the user to noboby, so reset to root
USER root

# Based on https://github.com/GoogleCloudPlatform/python-docker/blob/master/Dockerfile
# Link above installs stuff for Python, virtualenv
# Also kludged in stuff for Osmium and Git
RUN apt-get -q update && \
 apt-get install --no-install-recommends -y -q \
   libbz2-dev python2.7 python2.7-dev cmake python-pip build-essential git mercurial \
   libffi-dev libssl-dev libxml2-dev \
   libxslt1-dev libpq-dev libmysqlclient-dev libcurl4-openssl-dev \
   libjpeg-dev zlib1g-dev libpng12-dev \
   gfortran libblas-dev liblapack-dev libatlas-dev libquadmath0 \
   libfreetype6-dev pkg-config swig \
   zlib1g-dev libshp-dev libsqlite3-dev \
   libgd2-xpm-dev libexpat1-dev libgeos-dev libgeos++-dev libxml2-dev \
   libsparsehash-dev libv8-dev libicu-dev libgdal1-dev \
   libprotobuf-dev protobuf-compiler devscripts debhelper \
   fakeroot doxygen libboost-dev libboost-all-dev git-core \
   && \
 apt-get clean

# copy requirements.txt and run pip to install all dependencies into the virtualenv.
ADD requirements_base.txt /DeepOSM/requirements_base.txt
ADD requirements_gpu.txt /DeepOSM/requirements_gpu.txt
RUN pip install -r /DeepOSM/requirements_gpu.txt
RUN ln -s /home/vmagent/src /DeepOSM

# install libosmium and pyosmium bindings
RUN git clone https://github.com/osmcode/libosmium /libosmium
RUN cd /libosmium && mkdir build && cd build && cmake .. && make
RUN git clone https://github.com/osmcode/pyosmium.git /pyosmium
RUN cd /pyosmium && pwd && python setup.py install

# update PYTHONPATH
ENV PYTHONPATH /DeepOSM:/DeepOSM/src:$PYTHONPATH
ENV GEO_DATA_DIR /DeepOSM/data

# https://github.com/NVIDIA/nvidia-docker/blob/master/ubuntu-14.04/cuda/7.5/runtime/Dockerfile
LABEL com.nvidia.volumes.needed="nvidia_driver"

ENV NVIDIA_GPGKEY_SUM bd841d59a27a406e513db7d405550894188a4c1cd96bf8aa4f82f1b39e0b5c1c
ENV NVIDIA_GPGKEY_FPR 889bee522da690103c4b085ed88c3d385c37d3be

RUN apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/GPGKEY && \
    apt-key adv --export --no-emit-version -a $NVIDIA_GPGKEY_FPR | tail -n +2 > cudasign.pub && \
    echo "$NVIDIA_GPGKEY_SUM  cudasign.pub" | sha256sum -c --strict - && rm cudasign.pub && \
    echo "deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64 /" > /etc/apt/sources.list.d/cuda.list

ENV CUDA_VERSION 7.5
LABEL com.nvidia.cuda.version="7.5"

ENV CUDA_PKG_VERSION 7-5=7.5-18
RUN apt-get update && apt-get install -y --no-install-recommends --force-yes \
        cuda-nvrtc-$CUDA_PKG_VERSION \
        cuda-cusolver-$CUDA_PKG_VERSION \
        cuda-cublas-$CUDA_PKG_VERSION \
        cuda-cufft-$CUDA_PKG_VERSION \
        cuda-curand-$CUDA_PKG_VERSION \
        cuda-cusparse-$CUDA_PKG_VERSION \
        cuda-npp-$CUDA_PKG_VERSION \
        cuda-cudart-$CUDA_PKG_VERSION && \
    ln -s cuda-$CUDA_VERSION /usr/local/cuda && \
    rm -rf /var/lib/apt/lists/*

RUN echo "/usr/local/cuda/lib" >> /etc/ld.so.conf.d/cuda.conf && \
    echo "/usr/local/cuda/lib64" >> /etc/ld.so.conf.d/cuda.conf && \
    ldconfig

RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64:${LD_LIBRARY_PATH}

# https://github.com/NVIDIA/nvidia-docker/blob/master/ubuntu-14.04/cuda/7.5/devel/Dockerfile

RUN apt-get update && apt-get install -y --no-install-recommends --force-yes \
        cuda-core-$CUDA_PKG_VERSION \
        cuda-misc-headers-$CUDA_PKG_VERSION \
        cuda-command-line-tools-$CUDA_PKG_VERSION \
        cuda-license-$CUDA_PKG_VERSION \
        cuda-nvrtc-dev-$CUDA_PKG_VERSION \
        cuda-cusolver-dev-$CUDA_PKG_VERSION \
        cuda-cublas-dev-$CUDA_PKG_VERSION \
        cuda-cufft-dev-$CUDA_PKG_VERSION \
        cuda-curand-dev-$CUDA_PKG_VERSION \
        cuda-cusparse-dev-$CUDA_PKG_VERSION \
        cuda-npp-dev-$CUDA_PKG_VERSION \
        cuda-cudart-dev-$CUDA_PKG_VERSION \
        cuda-driver-dev-$CUDA_PKG_VERSION && \
    cd /tmp && apt-get download gpu-deployment-kit && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir /tmp/gpu-deployment-kit && cd /tmp/gpu-deployment-kit && \
    dpkg -x /tmp/gpu-deployment-kit_*.deb . && \
    mv usr/include/nvidia/gdk/* /usr/local/cuda/include && \
    mv usr/src/gdk/nvml/lib/* /usr/local/cuda/lib64/stubs && \
    rm -rf /tmp/gpu-deployment-kit*

ENV LIBRARY_PATH /usr/local/cuda/lib64/stubs:${LIBRARY_PATH}

RUN apt-get update && apt-get install -y --no-install-recommends --force-yes wget

# https://hub.docker.com/r/kaixhin/cudnn/~/dockerfile/
ENV CUDA_REPO_PKG=cuda-repo-ubuntu1404_6.5-14_amd64.deb 
RUN wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/$CUDA_REPO_PKG && \
  dpkg -i $CUDA_REPO_PKG

ENV ML_REPO_PKG=nvidia-machine-learning-repo_4.0-2_amd64.deb 

RUN wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1404/x86_64/$ML_REPO_PKG && \
  dpkg -i $ML_REPO_PKG && \
  apt-get update && apt-get install -y libcudnn4 libcudnn4-dev

# add-apt-repository requires software-properties-common
# compiling tensorflow requires rsync
RUN apt-get install --no-install-recommends -y -q curl zip unzip software-properties-common rsync

# adapted for java 8: http://stackoverflow.com/questions/25019183/docker-java7-install-fail
RUN apt-get update
RUN add-apt-repository ppa:webupd8team/java -y
RUN apt-get update
RUN echo debconf shared/accepted-oracle-license-v1-1 select true | debconf-set-selections
# I've had this command fail multiple times before it works, download times out.
RUN apt-get install oracle-java8-installer -y

# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile.devel-gpu
# Running bazel inside a `docker build` command causes trouble, cf:
#   https://github.com/bazelbuild/bazel/issues/134
# The easiest solution is to set up a bazelrc file forcing --batch.
RUN echo "startup --batch" >>/root/.bazelrc
# Similarly, we need to workaround sandboxing issues:
#   https://github.com/bazelbuild/bazel/issues/418
RUN echo "build --spawn_strategy=standalone --genrule_strategy=standalone" \
    >>/root/.bazelrc
ENV BAZELRC /root/.bazelrc
# Install the most recent bazel release.
ENV BAZEL_VERSION 0.2.1
WORKDIR /
RUN mkdir /bazel && \
    cd /bazel && \
    curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh && \
    curl -fSsL -o /bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE.txt && \
    chmod +x bazel-*.sh && \
    ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh && \
    cd / && \
    rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh

# Download and build TensorFlow.
RUN git clone --recursive https://github.com/tensorflow/tensorflow.git && \
    cd tensorflow && \
    git checkout r0.8
WORKDIR /tensorflow

# Set up CUDA variables
ENV CUDA_PATH /usr/local/cuda

# Configure the build for our CUDA configuration.
ENV CUDA_TOOLKIT_PATH /usr/local/cuda
ENV CUDNN_INSTALL_PATH /usr/local/cuda
ENV TF_NEED_CUDA 1

RUN ./configure && \
    bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package && \
    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \
    pip install --upgrade /tmp/pip/tensorflow-*.whl

# Jupyter has issues with being run directly:
#    https://github.com/ipython/ipython/issues/7062
# We just add a little wrapper script, and set up our jupyter config.
COPY run_jupyter.sh /
COPY jupyter_notebook_config.py /root/.jupyter/
EXPOSE 8888

# install s3cmd, used to ls the RequesterPays bucket 
RUN apt-get --no-install-recommends -y -q install wget
RUN wget http://netix.dl.sourceforge.net/project/s3tools/s3cmd/1.6.0/s3cmd-1.6.0.tar.gz && tar xvfz s3cmd-1.6.0.tar.gz && cd s3cmd-1.6.0 && python setup.py install

# copy s3cmd config defaults to docker, which will later be
# updated with AWS credentials by Python inside docker
COPY s3config-default /root/.s3cfg

# https://github.com/tflearn/tflearn/issues/55
# its different if we do AWS GPUs
RUN apt-get install libhdf5-dev

ADD . /DeepOSM
WORKDIR /DeepOSM
